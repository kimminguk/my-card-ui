"""
=================================================================
ğŸ“¡ AE WIKI - API ê´€ë¦¬ì ëª¨ë“ˆ (api_manager.py)
=================================================================

ğŸ“‹ íŒŒì¼ ì—­í• :
- AI API í†µì‹  ê´€ë¦¬ (RAG API, LLM API)
- ì‹¤ì œ API í˜¸ì¶œ ì²˜ë¦¬
- ì±—ë´‡ë³„ API ì„¤ì • ë° ì‘ë‹µ í¬ë§·íŒ…

ğŸ”— ì£¼ìš” ì»´í¬ë„ŒíŠ¸:
- RAG API í˜¸ì¶œ ë° ë¬¸ì„œ ê²€ìƒ‰
- LLM API í˜¸ì¶œ ë° ì‘ë‹µ ìƒì„±
- ì¶œì²˜ ì •ë³´ í¬ë§·íŒ…

ğŸ› ï¸ ê°œì„ ì‚¬í•­ (2025-10-13):
1. ë°©ì–´ì  API ì‘ë‹µ íŒŒì‹± - í‚¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ë‹¤ì¤‘ ê²½ë¡œ ì§€ì›
2. Accept í—¤ë” ìˆ˜ì • - ìŠ¤íŠ¸ë¦¬ë° ë¹„í™œì„±í™” ì‹œ application/json ì‚¬ìš©
3. source_dataë¥¼ LLM í”„ë¡¬í”„íŠ¸ì— í¬í•¨ - ì‹ ë¢°ì„± í–¥ìƒ
4. RAG ì‘ë‹µ íŒŒì‹± fallback ì¶”ê°€ - ë‹¤ì–‘í•œ í•„ë“œëª… ì§€ì›
5. ì‹¤ì œ ì—ëŸ¬ ë©”ì‹œì§€ ë…¸ì¶œ - ë””ë²„ê¹… ìš©ì´ì„± í–¥ìƒ
6. ìƒì„¸í•œ ë””ë²„ê¹… ë¡œê·¸ - í„°ë¯¸ë„ ì¶œë ¥ìœ¼ë¡œ íë¦„ ì¶”ì 
"""

import requests
import time
import logging
import uuid
import json
import traceback
from datetime import datetime
from typing import Dict, List, Optional, Any, Union

from config import API_CONFIG, TEST_CONFIG, get_index_system_prompt, get_index_config, get_index_rag_name

logger = logging.getLogger(__name__)

# ========================================
# ë””ë²„ê¹… ì„¤ì •
# ========================================
DEBUG_MODE = True  # Falseë¡œ ì„¤ì •í•˜ë©´ ìƒì„¸ ë¡œê·¸ ë¹„í™œì„±í™”

def debug_print(message: str, data: Any = None, level: str = "INFO"):
    """
    ë””ë²„ê¹…ìš© ì¶œë ¥ í•¨ìˆ˜ - í„°ë¯¸ë„ì— ìƒì„¸ ì •ë³´ ì¶œë ¥

    Args:
        message: ì¶œë ¥í•  ë©”ì‹œì§€
        data: ì¶œë ¥í•  ë°ì´í„° (dict, list ë“±)
        level: ë¡œê·¸ ë ˆë²¨ (INFO, WARNING, ERROR)
    """
    if DEBUG_MODE:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
        level_emoji = {"INFO": "â„¹ï¸", "WARNING": "âš ï¸", "ERROR": "âŒ"}.get(level, "ğŸ“")

        print(f"\n{'='*80}")
        print(f"{level_emoji} [{level} {timestamp}] {message}")

        if data is not None:
            if isinstance(data, (dict, list)):
                try:
                    print(json.dumps(data, indent=2, ensure_ascii=False))
                except Exception as e:
                    print(f"[JSON ì§ë ¬í™” ì‹¤íŒ¨: {e}]")
                    print(str(data))
            else:
                print(str(data))
        print(f"{'='*80}\n")


def safe_get_nested(data, *path, default=None):
    """
    dict/list ëª¨ë‘ ì§€ì›í•˜ëŠ” ì•ˆì „í•œ ì¤‘ì²© ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜

    Args:
        data: ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸
        *path: ì ‘ê·¼í•  ê²½ë¡œ (str: ë”•ì…”ë„ˆë¦¬ í‚¤, int: ë¦¬ìŠ¤íŠ¸ ì¸ë±ìŠ¤)
        default: ê¸°ë³¸ê°’

    Returns:
        ì¶”ì¶œëœ ê°’ ë˜ëŠ” ê¸°ë³¸ê°’

    Examples:
        safe_get_nested(obj, "choices", 0, "message", "content")
        safe_get_nested(obj, "hits", "hits", 0, "_source", "title")
    """
    cur = data
    for key in path:
        if isinstance(cur, dict) and isinstance(key, str):
            if key not in cur:
                return default
            cur = cur[key]
        elif isinstance(cur, list) and isinstance(key, int):
            if key < 0 or key >= len(cur):
                return default
            cur = cur[key]
        else:
            return default
    return cur if cur is not None else default


# ========================================
# Confluence ê¸°ë³¸ URL
# ========================================
CONFLUENCE_BASE = "https://confluence.samsungds.net/spaces/AppEngineeringTeam/pages/"

def sanitize_llm_markdown(text: str) -> str:
    """LLM ì‘ë‹µ ë‚´ HTML ì¤„ë°”ê¿ˆ/ê²½ëŸ‰ íƒœê·¸ë¥¼ Markdown ì¹œí™”ì ìœ¼ë¡œ ì •ë¦¬"""
    if not isinstance(text, str):
        return text

    # 1) br ë³€í˜• ì „ë¶€ ê°œí–‰ìœ¼ë¡œ
    text = text.replace("<br />", "\n").replace("<br/>", "\n").replace("<br>", "\n")

    # 2) p íƒœê·¸ â†’ ë¹ˆ ì¤„
    text = text.replace("</p>", "\n\n").replace("<p>", "")

    # 3) li íƒœê·¸ â†’ ë¶ˆë¦¿
    text = text.replace("</li>", "").replace("<li>", "â€¢ ")

    # 4) ul/ol ì œê±°
    text = text.replace("<ul>", "").replace("</ul>", "").replace("<ol>", "").replace("</ol>", "")

    # 5) ì—°ì† ê°œí–‰ ì •ë¦¬(ì„ íƒ)
    while "\n\n\n" in text:
        text = text.replace("\n\n\n", "\n\n")

    return text.strip()


# ========================================
# RAG ì‘ë‹µ ë²”ìš© íŒŒì„œ
# ========================================
def _extract_hits_from_rag_response(response, *, debug=False):
    """
    ì„œë²„ ì‘ë‹µ í¬ë§· ë³€í™”ì— ëŒ€ì‘í•˜ëŠ” ìœ ì—°í•œ hits ì¶”ì¶œê¸°.
    ë°˜í™˜: List[dict] (ES hit ê°ì²´ ë¦¬ìŠ¤íŠ¸)
    """
    try:
        data = response.json()
    except Exception:
        try:
            data = json.loads(response.text)
        except Exception:
            if debug:
                print("[RAG] ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨:", response.text[:1000])
            raise ValueError("RAG ì‘ë‹µì´ JSONì´ ì•„ë‹™ë‹ˆë‹¤.")

    if debug:
        try:
            print("[RAG] top-level keys:", list(data.keys()))
        except Exception:
            pass

    # ê³¼ê±° í¬ë§·: {"message": "{\"hits\": {...}}"}
    if isinstance(data, dict) and "message" in data:
        msg = data["message"]
        try:
            inner = json.loads(msg) if isinstance(msg, str) else msg
        except Exception:
            if debug:
                print("[RAG] message ì¬íŒŒì‹± ì‹¤íŒ¨:", type(msg), str(msg)[:300])
            raise ValueError("RAG ì‘ë‹µì˜ message í•„ë“œ JSON íŒŒì‹± ì‹¤íŒ¨")
        if "hits" in inner and "hits" in inner["hits"]:
            return inner["hits"]["hits"]

    # ì¼ë°˜ í¬ë§·: {"hits": {"hits": [...]}}
    if isinstance(data, dict) and "hits" in data and isinstance(data["hits"], dict) and "hits" in data["hits"]:
        return data["hits"]["hits"]

    # ë˜í•‘ í¬ë§·: {"data": {"hits": {"hits": [...]}}}
    cur = data
    for key in ("data", "result", "payload"):
        if isinstance(cur, dict) and key in cur:
            cur = cur[key]
    if isinstance(cur, dict) and "hits" in cur and isinstance(cur["hits"], dict) and "hits" in cur["hits"]:
        return cur["hits"]["hits"]

    if debug:
        print("[RAG] ì¸ì‹ ë¶ˆê°€ ì‘ë‹µ ìƒ˜í”Œ:", json.dumps(data, ensure_ascii=False)[:1000])
    raise KeyError("RAG ì‘ë‹µì—ì„œ hits ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


# ========================================
# LLM ì‘ë‹µ ë²”ìš© íŒŒì„œ
# ========================================
def _extract_llm_text(result, *, debug=False) -> str:
    """
    ë‹¤ì–‘í•œ LLM ì‘ë‹µ í¬ë§·ì—ì„œ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì•„ì„œ ë¬¸ìì—´ë¡œ ë°˜í™˜.
    ì§€ì›: choices[0].message.content(str|list), choices[0].text,
         tool_calls/function_call(ìš”ì•½), refusal, Responses API ìŠ¤íƒ€ì¼ ë“±
    """
    if not isinstance(result, dict):
        return ""

    if debug:
        try:
            print("[LLM] top-level keys:", list(result.keys()))
        except Exception:
            pass

    # 1) Chat Completions í‘œì¤€ ê³„ì—´
    try:
        choices = result.get("choices")
        if isinstance(choices, list) and choices:
            c0 = choices[0]
            if debug:
                try:
                    print("[LLM] choices[0] keys:", list(c0.keys()))
                    if isinstance(c0.get("message"), dict):
                        print("[LLM] choices[0].message keys:", list(c0["message"].keys()))
                except Exception:
                    pass

            # 1-1) message.content (string)
            msg = c0.get("message") or {}
            content = msg.get("content")
            if isinstance(content, str) and content.strip():
                return content

            # 1-2) message.content (list of parts)
            if isinstance(content, list):
                parts = []
                for p in content:
                    if isinstance(p, dict) and isinstance(p.get("text"), str) and p["text"].strip():
                        parts.append(p["text"])
                    elif isinstance(p, str) and p.strip():
                        parts.append(p)
                if parts:
                    return "\n".join(parts)

            # 1-3) tool_calls / function_callë§Œ ìˆê³  contentê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°
            tool_calls = msg.get("tool_calls") or []
            function_call = msg.get("function_call")
            if tool_calls or function_call:
                try:
                    if tool_calls:
                        tc = tool_calls[0]
                        fn_name = tc.get("function", {}).get("name", "tool")
                        fn_args = tc.get("function", {}).get("arguments", "")
                        if isinstance(fn_args, dict):
                            fn_args = json.dumps(fn_args, ensure_ascii=False)
                        return f"(ë„êµ¬ í˜¸ì¶œ: {fn_name} args={fn_args})"
                    if function_call:
                        fn_name = function_call.get("name", "function")
                        fn_args = function_call.get("arguments", "")
                        if isinstance(fn_args, dict):
                            fn_args = json.dumps(fn_args, ensure_ascii=False)
                        return f"(í•¨ìˆ˜ í˜¸ì¶œ: {fn_name} args={fn_args})"
                except Exception:
                    pass

            # 1-4) refusalì´ ë³„ë„ í•„ë“œë¡œ ì˜¨ ê²½ìš°
            refusal = msg.get("refusal")
            if isinstance(refusal, str) and refusal.strip():
                return f"(ê±°ë¶€ ì‚¬ìœ )\n{refusal}"

            # 1-5) êµ¬í˜•/í˜¸í™˜: choices[0].text
            if isinstance(c0.get("text"), str) and c0["text"].strip():
                return c0["text"]

            # 1-6) finish_reasonì´ content_filter ë“±ìœ¼ë¡œ contentê°€ ë¹„ëŠ” ê²½ìš°
            finish_reason = c0.get("finish_reason")
            if finish_reason and str(finish_reason) != "stop":
                return f"(finish_reason={finish_reason})"
    except Exception as e:
        if debug:
            print("[LLM] ChatCompletions parse error:", repr(e))

    # 2) Responses API ê³„ì—´
    try:
        output = result.get("output")
        if isinstance(output, list) and output:
            o0 = output[0]
            cnt = o0.get("content")
            if isinstance(cnt, list) and cnt:
                parts = []
                for p in cnt:
                    if isinstance(p, dict) and isinstance(p.get("text"), str) and p["text"].strip():
                        parts.append(p["text"])
                if parts:
                    return "\n".join(parts)
    except Exception as e:
        if debug:
            print("[LLM] Responses parse error:", repr(e))

    return ""


# ========================================
# ì¶œì²˜ í¬ë§·íŒ… í•¨ìˆ˜
# ========================================
def format_source_citations(source_data: List[dict], chatbot_type: str = "ae_wiki") -> str:
    """ì¶œì²˜ ì •ë³´ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…"""
    if not source_data:
        return ""
    lines = []
    for i, s in enumerate(source_data, 1):
        t = s.get("title", f"ë¬¸ì„œ_{i}")
        u = s.get("source_url", "")
        if not u and s.get("doc_id"):
            u = f"{CONFLUENCE_BASE}{s['doc_id']}"
        if u:
            lines.append(f"{i}. [{t}]({u})")
        else:
            lines.append(f"{i}. {t}")
    return "\n".join(lines)


# ========================================
# LLM API í˜¸ì¶œ í•¨ìˆ˜ (ê°œì„  ë²„ì „)
# ========================================
def call_llm_api(
    user_message: str,
    retrieve_data: List[str],
    chat_history: list = None,
    source_data: List[dict] = None,
    user_id: str = None,
    custom_system_prompt: str = None,
    chatbot_type: str = "ae_wiki"
) -> str:
    """
    ğŸ¯ ëª©ì : LLM APIë¥¼ í˜¸ì¶œí•˜ì—¬ RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±

    ğŸ“Š ì…ë ¥:
    - user_message (str): ì‚¬ìš©ì ì§ˆë¬¸
    - retrieve_data (List[str]): RAGì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© ë¦¬ìŠ¤íŠ¸
    - chat_history (list): ì´ì „ ëŒ€í™” ê¸°ë¡ (ìµœëŒ€ 10í„´)
    - source_data (List[dict]): ì¶œì²˜ ì •ë³´ (URL, ì œëª© ë“±) - LLM í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë¨
    - user_id (str): ì‚¬ìš©ì ì‹ë³„ì
    - custom_system_prompt (str): ì»¤ìŠ¤í…€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    - chatbot_type (str): ì±—ë´‡ íƒ€ì… ("ae_wiki", "glossary", "jedec")

    ğŸ“¤ ì¶œë ¥:
    - str: LLMì´ ìƒì„±í•œ ë‹µë³€ í…ìŠ¤íŠ¸

    ğŸ›¡ï¸ ê°œì„ ì‚¬í•­:
    - ë°©ì–´ì  ì‘ë‹µ íŒŒì‹± (ë¬¸ì œ 1 í•´ê²°)
    - Accept í—¤ë” ìˆ˜ì • (ë¬¸ì œ 2 í•´ê²°)
    - source_data í¬í•¨ (ë¬¸ì œ 3 í•´ê²°)
    - ì‹¤ì œ ì—ëŸ¬ ë…¸ì¶œ (ë¬¸ì œ 5 í•´ê²°)
    - ìƒì„¸ ë””ë²„ê¹… ë¡œê·¸ (ë¬¸ì œ 7 í•´ê²°)
    """

    debug_print("ğŸš€ LLM API í˜¸ì¶œ ì‹œì‘", {
        "user_message": user_message[:100] + "..." if len(user_message) > 100 else user_message,
        "chatbot_type": chatbot_type,
        "user_id": user_id,
        "retrieve_data_count": len(retrieve_data) if retrieve_data else 0,
        "source_data_count": len(source_data) if source_data else 0,
        "chat_history_count": len(chat_history) if chat_history else 0
    })

    try:
        # STEP 1: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        system_prompt = custom_system_prompt or get_index_system_prompt(chatbot_type)
        debug_print("ğŸ“ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ", {
            "prompt_length": len(system_prompt),
            "prompt_preview": system_prompt[:150] + "..."
        })

        # STEP 2: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©
        if retrieve_data:
            combined_context = "\n\n".join([f"ë¬¸ì„œ {i+1}:\n{doc}" for i, doc in enumerate(retrieve_data)])
            debug_print("ğŸ“š ê²€ìƒ‰ ë¬¸ì„œ ê²°í•© ì™„ë£Œ", {
                "document_count": len(retrieve_data),
                "total_length": len(combined_context)
            })
        else:
            combined_context = "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            debug_print("âš ï¸ ê²€ìƒ‰ëœ ë¬¸ì„œ ì—†ìŒ", level="WARNING")

        # STEP 3: ì¶œì²˜ ì •ë³´ë¥¼ í¬ë§·íŒ… (ë¬¸ì œ 3 í•´ê²° - source_dataë¥¼ LLMì— ë°˜ì˜)
        source_citations = ""
        if source_data:
            source_citations = format_source_citations(source_data, chatbot_type)
            debug_print("ğŸ”— ì¶œì²˜ ì •ë³´ í¬ë§·íŒ… ì™„ë£Œ", {
                "source_count": len(source_data),
                "citations_length": len(source_citations)
            })

        # STEP 4: messages ë°°ì—´ êµ¬ì„±
        messages = []

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        messages.append({
            "role": "system",
            "content": system_prompt
        })

        # ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶”ê°€
        if chat_history:
            recent_history = chat_history[-20:] if len(chat_history) > 20 else chat_history
            messages.extend(recent_history)
            debug_print("ğŸ’¬ ëŒ€í™” ê¸°ë¡ ì¶”ê°€", {"history_messages": len(recent_history)})

        # í˜„ì¬ ì§ˆë¬¸ êµ¬ì„± (RAG ë¬¸ì„œ + ì¶œì²˜ ì •ë³´ í¬í•¨)
        current_user_message = f"""[ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ]
{combined_context}

[í˜„ì¬ ì§ˆë¬¸]
{user_message}

ìœ„ì˜ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."""

        # ì¶œì²˜ ì •ë³´ê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€ (ë¬¸ì œ 3 í•´ê²°)
        if source_citations:
            current_user_message += f"\n\n{source_citations}"

        messages.append({
            "role": "user",
            "content": current_user_message
        })

        debug_print("ğŸ“¨ Messages ë°°ì—´ êµ¬ì„± ì™„ë£Œ", {
            "total_messages": len(messages),
            "user_message_length": len(current_user_message)
        })

        # STEP 5: API í˜¸ì¶œ ì„¤ì •
        api_config = API_CONFIG.get("llm_api", {})
        if not api_config:
            raise ValueError("API_CONFIGì— 'llm_api' ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")

        base_url = api_config.get("base_url")
        if not base_url:
            raise ValueError("LLM API base_urlì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # í—¤ë” êµ¬ì„±
        headers_config = api_config.get("headers", {})

        # ë¬¸ì œ 2 í•´ê²°: ìŠ¤íŠ¸ë¦¬ë° ë¹„í™œì„±í™” ì‹œ Acceptë¥¼ application/jsonìœ¼ë¡œ ë³€ê²½
        accept_header = "application/json"  # stream=Falseì´ë¯€ë¡œ JSONìœ¼ë¡œ ë³€ê²½

        headers = {
            "x-dep-ticket": api_config.get("credential_key", ""),
            "Send-System-Name": headers_config.get("Send-System-Name", ""),
            "User-Id": user_id or headers_config.get("User-Id", ""),
            "User-Type": headers_config.get("User-Type", "AD_ID"),
            "Prompt-Msg-Id": str(uuid.uuid4()),
            "Completion-Msg-Id": str(uuid.uuid4()),
            "Accept": accept_header,  # ë¬¸ì œ 2 í•´ê²°
            "Content-Type": "application/json"
        }

        payload = {
            "model": api_config.get("model", "openai/gpt-oss-120b"),
            "messages": messages,
            "temperature": 0.1,
            "max_tokens": 6000,
            "stream": False
        }

        debug_print("ğŸ“¤ LLM API ìš”ì²­ ì¤€ë¹„", {
            "url": base_url,
            "model": payload["model"],
            "temperature": payload["temperature"],
            "max_tokens": payload["max_tokens"],
            "stream": payload["stream"],
            "headers": {k: v[:50] + "..." if len(str(v)) > 50 else v for k, v in headers.items()}
        })

        # STEP 6: API í˜¸ì¶œ ì‹¤í–‰
        debug_print("ğŸŒ LLM API í˜¸ì¶œ ì¤‘...")

        response = requests.post(
            base_url,
            headers=headers,
            json=payload,
            timeout=30
        )

        debug_print("ğŸ“¥ LLM API ì‘ë‹µ ìˆ˜ì‹ ", {
            "status_code": response.status_code,
            "headers": dict(response.headers),
            "response_length": len(response.text) if response.text else 0
        })

        # STEP 7: ì‘ë‹µ ì²˜ë¦¬ (ë²”ìš© íŒŒì„œ ì‚¬ìš©)
        if response.status_code == 200:
            try:
                result = response.json()

                # ê´€ì°°ìš©: choices[0] êµ¬ì¡°
                try:
                    if isinstance(result.get("choices"), list) and result["choices"]:
                        c0 = result["choices"][0]
                        print("[LLM] choices[0] keys:", list(c0.keys()))
                        if isinstance(c0.get("message"), dict):
                            print("[LLM] choices[0].message keys:", list(c0["message"].keys()))
                except Exception:
                    pass

                content = _extract_llm_text(result, debug=True)
                if content and isinstance(content, str):
                    debug_print("âœ… LLM ë‹µë³€ ìƒì„± ì„±ê³µ", {
                        "content_length": len(content),
                        "content_preview": content[:200] + "..." if len(content) > 200 else content
                    })

                    # ì¶œì²˜ ë°ì´í„° ì¶”ê°€
                    citations_source = source_data or []

                    # í•˜ë‹¨ ì¶œì²˜ ì„¹ì…˜ ìƒì„± ë° ë¶™ì´ê¸°
                    try:
                        citations_md = format_source_citations(citations_source, chatbot_type)
                    except Exception:
                        citations_md = ""

                    final_answer = content + ("\n\n---\n**ì¶œì²˜**\n" + citations_md if citations_md else "")
                    return final_answer

                # content ëª» ì°¾ì€ ê²½ìš°: í´ë°± ì²˜ë¦¬
                try:
                    # í…ìŠ¤íŠ¸ ë³¸ë¬¸ì´ ì—†ì„ ë•Œ, ìµœì†Œ íŒíŠ¸ë¼ë„ ë§Œë“¤ì–´ì„œ ë°˜í™˜
                    choices = result.get("choices") or []
                    c0 = choices[0] if choices else {}
                    msg = c0.get("message") or {}
                    finish_reason = c0.get("finish_reason")
                    tool_calls = msg.get("tool_calls") or []
                    function_call = msg.get("function_call")

                    hint_lines = []
                    if finish_reason:
                        hint_lines.append(f"finish_reason={finish_reason}")
                    if tool_calls:
                        try:
                            fn_name = tool_calls[0].get("function", {}).get("name", "tool")
                            hint_lines.append(f"tool_calls={fn_name}")
                        except Exception:
                            pass
                    if function_call:
                        try:
                            fn_name = function_call.get("name", "function")
                            hint_lines.append(f"function_call={fn_name}")
                        except Exception:
                            pass

                    hint = (", ".join(hint_lines)) if hint_lines else "ë³¸ë¬¸ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŒ"
                    content = f"(LLM ì‘ë‹µ ìš”ì•½: {hint})"

                    # ì¶œì²˜ ë¶™ì´ê¸°
                    citations_source = source_data or []
                    try:
                        citations_md = format_source_citations(citations_source, chatbot_type)
                    except Exception:
                        citations_md = ""

                    final_answer = content + ("\n\n---\n**ì¶œì²˜**\n" + citations_md if citations_md else "")
                    return final_answer

                except Exception:
                    # ë§ˆì§€ë§‰ ë°©ì–´ì„ : ê·¸ë˜ë„ ì‹¤íŒ¨í•˜ë©´ ê¸°ì¡´ ì˜¤ë¥˜ë¥¼ ìœ ì§€
                    top_keys = list(result.keys())
                    raise ValueError(f"LLM API ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜ - contentë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‘ë‹µ í‚¤: {top_keys}")

            except json.JSONDecodeError as e:
                error_msg = f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}\n\nì›ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸:\n{response.text[:1000]}"
                debug_print(error_msg, level="ERROR")
                logger.error(error_msg)
                raise ValueError(f"LLM API ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        else:
            # ë¬¸ì œ 5 í•´ê²°: ì‹¤ì œ HTTP ì—ëŸ¬ì™€ ì‘ë‹µ ë³¸ë¬¸ì„ ë…¸ì¶œ
            error_msg = f"âŒ LLM API í˜¸ì¶œ ì‹¤íŒ¨\n\nHTTP Status: {response.status_code}\nReason: {response.reason}\n\nì‘ë‹µ ë³¸ë¬¸:\n{response.text[:1000]}"
            debug_print(error_msg, level="ERROR")
            logger.error(error_msg)
            raise requests.HTTPError(f"LLM API í˜¸ì¶œ ì‹¤íŒ¨ - Status: {response.status_code}, Reason: {response.reason}, Body: {response.text[:500]}")

    except requests.Timeout as e:
        error_msg = f"âŒ LLM API íƒ€ì„ì•„ì›ƒ (30ì´ˆ ì´ˆê³¼)\n\nì˜ˆì™¸: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"
        debug_print(error_msg, level="ERROR")
        logger.error(error_msg)
        raise TimeoutError(f"LLM API íƒ€ì„ì•„ì›ƒ: {str(e)}")

    except requests.RequestException as e:
        error_msg = f"âŒ LLM API ìš”ì²­ ì˜ˆì™¸\n\nì˜ˆì™¸: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"
        debug_print(error_msg, level="ERROR")
        logger.error(error_msg)
        raise requests.RequestException(f"LLM API ìš”ì²­ ì˜ˆì™¸: {str(e)}")

    except Exception as e:
        error_msg = f"âŒ LLM API ì˜ˆìƒì¹˜ ëª»í•œ ì˜ˆì™¸\n\nì˜ˆì™¸ íƒ€ì…: {type(e).__name__}\nì˜ˆì™¸ ë‚´ìš©: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"
        debug_print(error_msg, level="ERROR")
        logger.error(error_msg)
        raise Exception(f"LLM API ì˜ˆìƒì¹˜ ëª»í•œ ì˜ˆì™¸ [{type(e).__name__}]: {str(e)}")


# ========================================
# RAG API í˜¸ì¶œ í•¨ìˆ˜ (ê°œì„  ë²„ì „)
# ========================================
def call_rag_api_with_chatbot_type(user_message: str, chatbot_type: str) -> dict:
    """
    ğŸ¯ ëª©ì : ì±—ë´‡ íƒ€ì…ë³„ RAG API í˜¸ì¶œí•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰

    ğŸ“Š ì…ë ¥:
    - user_message (str): ì‚¬ìš©ì ì§ˆë¬¸
    - chatbot_type (str): ì±—ë´‡ íƒ€ì… (ae_wiki, glossary, jedec, quality, test_engineering)

    ğŸ“¤ ì¶œë ¥:
    - dict: {"documents": [ë¬¸ì„œë“¤], "source_info": [ì¶œì²˜ì •ë³´ë“¤]}

    ğŸ›¡ï¸ ê°œì„ ì‚¬í•­:
    - fallback íŒŒì‹± ë¡œì§ ì¶”ê°€ (ë¬¸ì œ 4 í•´ê²°)
    - ì‹¤ì œ ì—ëŸ¬ ë…¸ì¶œ (ë¬¸ì œ 5 í•´ê²°)
    - ìƒì„¸ ë””ë²„ê¹… ë¡œê·¸ (ë¬¸ì œ 7 í•´ê²°)
    """

    debug_print("ğŸ” RAG API í˜¸ì¶œ ì‹œì‘", {
        "user_message": user_message[:100] + "..." if len(user_message) > 100 else user_message,
        "chatbot_type": chatbot_type
    })

    try:
        # STEP 1: ì±—ë´‡ë³„ ì¸ë±ìŠ¤ëª… ë§¤í•‘
        index_name = get_index_rag_name(chatbot_type)
        if not index_name:
            error_msg = f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì±—ë´‡ íƒ€ì…: {chatbot_type}"
            debug_print(error_msg, level="WARNING")
            logger.warning(error_msg)
            return {"documents": [], "source_info": []}

        debug_print("ğŸ“‡ ì¸ë±ìŠ¤ ë§¤í•‘ ì™„ë£Œ", {
            "chatbot_type": chatbot_type,
            "index_name": index_name
        })

        # STEP 2: RAG API ì„¤ì •
        api_config = API_CONFIG.get("rag_api_common", {})
        if not api_config:
            raise ValueError("API_CONFIGì— 'rag_api_common' ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")

        base_url = api_config.get("base_url")
        if not base_url:
            raise ValueError("RAG API base_urlì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # í˜ì´ë¡œë“œ êµ¬ì„± (ìŠ¤í™ ì¤€ìˆ˜)
        index_name = (index_name or "").strip()

        # URL/ID í‚¤ëŠ” ì ˆëŒ€ ì œì™¸í•˜ì§€ ì•Šë„ë¡ í•„í„°ë§
        _raw_exclude = api_config.get("fields_exclude", ["v_merge_title_content"])
        fields_exclude = [k for k in _raw_exclude if k not in {"source_url", "url", "doc_url", "link", "doc_id", "_id"}]

        payload = {
            "index_name": index_name,
            "permission_groups": api_config.get("auth_list", ["ds"]),
            "query_text": user_message,
            "num_result_doc": api_config.get("num_result_doc", 5),
            "fields_exclude": fields_exclude,
        }

        print(f"[RAG] base_url={api_config.get('base_url','')}")
        print(f"[RAG] index_name='{index_name}'")
        print(f"[RAG] permission_groups={api_config.get('auth_list', [])}")
        print(f"[RAG] fields_exclude={fields_exclude}")

        # í—¤ë” êµ¬ì„±
        headers = {
            "Content-Type": "application/json",
            "x-dep-ticket": api_config.get("credential_key", ""),
            "api-key": api_config.get("api-key", "")
        }

        debug_print("ğŸ“¤ RAG API ìš”ì²­ ì¤€ë¹„", {
            "url": base_url,
            "index_name": index_name,
            "num_result_doc": payload["num_result_doc"],
            "query_length": len(user_message),
            "headers": {k: v[:50] + "..." if len(str(v)) > 50 else v for k, v in headers.items()}
        })

        # STEP 3: API í˜¸ì¶œ ì‹¤í–‰
        debug_print("ğŸŒ RAG API í˜¸ì¶œ ì¤‘...")

        response = requests.post(
            base_url,
            headers=headers,
            json=payload,
            timeout=api_config.get("timeout", 30)
        )

        debug_print("ğŸ“¥ RAG API ì‘ë‹µ ìˆ˜ì‹ ", {
            "status_code": response.status_code,
            "headers": dict(response.headers),
            "response_length": len(response.text) if response.text else 0
        })

        # STEP 4: ì‘ë‹µ ì²˜ë¦¬ (ë²”ìš© íŒŒì„œ ì‚¬ìš©)
        if response.status_code == 200:
            try:
                # í¬ë§· ë³€í™”ì— ì•ˆì „í•œ íŒŒì„œ
                hits = _extract_hits_from_rag_response(response, debug=True)
                debug_print("ğŸ“„ ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±", {"hit_count": len(hits)})

                documents: List[str] = []
                source_info: List[dict] = []

                # ì½˜í…ì¸ /ì œëª©/URL í›„ë³´ í‚¤
                CONTENT_KEYS = ["content", "merge_title_content", "v_merge_title_content", "body", "text"]
                TITLE_KEYS   = ["title", "doc_title", "name"]
                URL_KEYS     = ["source_url", "url", "doc_url", "link"]

                for i, hit in enumerate(hits):
                    src = hit.get("_source", {}) if isinstance(hit, dict) else {}

                    # content ì„ íƒ (ì²« ë§¤ì¹˜)
                    content = next((src.get(k) for k in CONTENT_KEYS if src.get(k)), "")
                    title   = next((src.get(k) for k in TITLE_KEYS   if src.get(k)), f"ë¬¸ì„œ_{i+1}")
                    url     = next((src.get(k) for k in URL_KEYS     if src.get(k)), "")

                    doc_id  = src.get("doc_id", "") or hit.get("_id", "")

                    # URLì´ ì—†ìœ¼ë©´ doc_idë¡œ ê°•ì œ ìƒì„±
                    if not url and doc_id:
                        url = f"{CONFLUENCE_BASE}{doc_id}"

                    # í•„ìˆ˜ ë³´ì •
                    if not isinstance(content, str):
                        content = str(content) if content is not None else ""
                    if not isinstance(title, str):
                        title = str(title) if title is not None else f"ë¬¸ì„œ_{i+1}"
                    if not isinstance(url, str):
                        url = str(url) if url is not None else ""

                    documents.append(content)

                    si = {
                        "title": title,
                        "doc_id": doc_id,
                        "score": hit.get("_score", 0),
                        "index": index_name,
                        "source_url": url
                    }
                    source_info.append(si)

                    # ë””ë²„ê·¸ ë¡œê·¸
                    try:
                        print(f"[RAG][{i}] source_info =", json.dumps(si, ensure_ascii=False))
                    except Exception as _e:
                        print(f"[RAG][{i}] source_info(print ì‹¤íŒ¨):", repr(_e))

                debug_print("âœ… RAG ê²€ìƒ‰ ì™„ë£Œ", {
                    "documents_count": len(documents),
                    "sources_count": len(source_info)
                })

                return {
                    "documents": documents if documents else ["ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."],
                    "source_info": source_info
                }

            except json.JSONDecodeError as e:
                error_msg = f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}\n\nì›ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸:\n{response.text[:1000]}"
                debug_print(error_msg, level="ERROR")
                logger.error(error_msg)
                raise ValueError(f"RAG API ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        else:
            # ë¬¸ì œ 5 í•´ê²°: ì‹¤ì œ HTTP ì—ëŸ¬ì™€ ì‘ë‹µ ë³¸ë¬¸ì„ ë…¸ì¶œ
            error_msg = f"âŒ RAG API í˜¸ì¶œ ì‹¤íŒ¨\n\nHTTP Status: {response.status_code}\nReason: {response.reason}\n\nì‘ë‹µ ë³¸ë¬¸:\n{response.text[:1000]}"
            debug_print(error_msg, level="ERROR")
            logger.error(error_msg)
            raise requests.HTTPError(f"RAG API í˜¸ì¶œ ì‹¤íŒ¨ - Status: {response.status_code}, Reason: {response.reason}, Body: {response.text[:500]}")

    except requests.Timeout as e:
        error_msg = f"âŒ RAG API íƒ€ì„ì•„ì›ƒ\n\nì˜ˆì™¸: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"
        debug_print(error_msg, level="ERROR")
        logger.error(error_msg)
        raise TimeoutError(f"RAG API íƒ€ì„ì•„ì›ƒ: {str(e)}")

    except requests.RequestException as e:
        error_msg = f"âŒ RAG API ìš”ì²­ ì˜ˆì™¸\n\nì˜ˆì™¸: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"
        debug_print(error_msg, level="ERROR")
        logger.error(error_msg)
        raise requests.RequestException(f"RAG API ìš”ì²­ ì˜ˆì™¸: {str(e)}")

    except Exception as e:
        error_msg = f"âŒ RAG API ì˜ˆìƒì¹˜ ëª»í•œ ì˜ˆì™¸\n\nì˜ˆì™¸ íƒ€ì…: {type(e).__name__}\nì˜ˆì™¸ ë‚´ìš©: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"
        debug_print(error_msg, level="ERROR")
        logger.error(error_msg)
        raise Exception(f"RAG API ì˜ˆìƒì¹˜ ëª»í•œ ì˜ˆì™¸ [{type(e).__name__}]: {str(e)}")


# ========================================
# ì¶œì²˜ ì •ë³´ í¬ë§·íŒ… í•¨ìˆ˜
# ========================================
def format_source_citations(source_data: List[dict], chatbot_type: str = "ae_wiki") -> str:
    """
    ğŸ¯ ëª©ì : ì±—ë´‡ë³„ ì¶œì²˜ ì •ë³´ë¥¼ ì ì ˆí•œ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…

    ğŸ“Š ì…ë ¥:
    - source_data: ì¶œì²˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    - chatbot_type: ì±—ë´‡ íƒ€ì…

    ğŸ“¤ ì¶œë ¥:
    - í¬ë§·íŒ…ëœ ì¶œì²˜ ì¸ìš© ë¬¸ìì—´
    """
    if not source_data:
        return ""

    citations = []

    for i, source in enumerate(source_data, 1):
        source_name = source.get("source", f"ë¬¸ì„œ {i}")

        if chatbot_type == "ae_wiki":
            # Confluence URL í¬í•¨
            if "confluence_url" in source:
                citations.append(f"ğŸ“„ **{source_name}** - [Confluence ë§í¬]({source['confluence_url']})")
            else:
                citations.append(f"ğŸ“„ **{source_name}**")

        elif chatbot_type == "jedec":
            # í˜ì´ì§€ ì •ë³´ í¬í•¨
            page_info = source.get("page", "")
            if page_info:
                citations.append(f"ğŸ“„ **{source_name}** ({page_info})")
            else:
                citations.append(f"ğŸ“„ **{source_name}**")

        else:
            # ê¸°ë³¸ í˜•ì‹
            citations.append(f"ğŸ“„ **{source_name}**")

        # ë‚ ì§œ ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if source.get("last_modified"):
            citations[-1] += f" (ìˆ˜ì •ì¼: {source['last_modified']})"

    if citations:
        return f"\n\n**ğŸ“š ì°¸ê³  ìë£Œ:**\n" + "\n".join(citations)
    else:
        return ""
